|Paper | Method | Group | Performance  |
|:---:|:---:|:---:|:---:|
|Shuiwang Ji et al.(2010) | 3D-Conv | View-based/<br/>Combination | 71.4\%(TRECVID),90.2\%(KTH)  |
|Baccouche et al.(2011) | 3D-Conv, LSTM | Sequential-based/<br/>RNN | 94.39\%(KTH)  |
|Two-Stream.(2014) | CNN, Two-stream | View-based/<br/>Augmentaion | 59.4\%(HMDB51), 88.0\%(UCF101)  |
|Andrej Karpathy et al.(2014) | CNN, Fusion | View-based/<br/>Combination | 41.9\%(Sports-1M)  |
|Jeff Donahue et al.(2015) | LSTM | Depth-based/<br/>Training-strategies | 82.66\%(UCF101)  |
|FstCN.(2015) | CNN | View-based/<br/>Factorization | 88.1\%(UCF101), 59.1\%(HMDB-51)  |
|C3D.(2015) | 3D-Conv | View-based/<br/>Combination | 90.4\%(UCF101), 85.2\%(Sports-1M)  |
|R*CNN.(2015) | CNN | View-based/<br/>Augmentaion |  90.2\%(Pascal VOC Aactions) |
|Georgia Gkioxari et al.(2015) | CNN, SVM | Depth-based/<br/>Training Strategies | 82.6\%(Pascal VOC Aactions)  |
|Christoph Feichtenhofer et al.(2016) | CNN, Two-stream | View-based/<br/>Combination | 93.5\%(UCF101), 69.2\%(HMDB51)  |
|Hammerla et al.(2016) | CNN, DNN, LSTM | Sequential-based/<br/>RNN | 93.7\%(PAMAP2), 76.0\%(Daphnet Gait), 74.50\%(Opportunity)  |
|TSN.(2016) | CNN | Sequential-based/<br/>Sampling | 69.4\%(HMDB51), 94.2\%(UCF101)  |
|UntrimmedNet.(2017) | CNN | Sequential-based/<br/>Sampling | 82.2\%(THUMOS14), 91.3\%(ActivityNet)  |
|Aenet.(2017) | CNN, 3D-Conv | View-based/<br/>Augmentaion | 85.3\%(UCF101)  |
|DOVF.(2017) | CNN | Sequential-based/<br/>Sampling | 75.0\%(HMDB51), 95.3\%(UCF101)  |
|I3D.(2017) | 3D-Conv | View-based/<br/>Combination | 80.2\%(HMDB51), 97.9\%(UCF101)  |
|P3D.(2017) | CNN | View-based/<br/>Factorization | 93.7\%(UCF101), 78.8\%(ActivityNet)  |
|TLE.(2017) | CNN, 3D-Conv | Sequential-based/<br/>Pooling | 71.1\%(HMDB51), 95.6\%(UCF101)  |
|Antoine Miech et al.(2017) | CNN, LSTM | Sequential-based/<br/>Pooling | 83.0\%(YouTube-8M)  |
|R(2+1)D.(2018) | ResNet | View-based/<br/>Factorization | 73.3\%(Sports-1M), 75.4\%(Kinetics), 97.3\%(UCF101), 78.7\%(HMDB51)  |
|CPMN.(2018) | CNN, Two-stream | View-based/<br/>Augmentation | 47.1\%(THUMOS14), 39.29\%(ActivityNet)  |
|PM-GAN.(2018) | CNN, GAN | View-based/<br/>Augmentation | 80.2\%(Infrared Visible)  |
|ECO.(2018) | CNN, 3D-Conv | Sequential-based/<br/>Sampling | 69.0\%(HMDB51), 93.6\%(UCF101)  |
|Potion.(2018) | 3D-Conv | View-based/<br/>Augmentaion | 82.3\%(HMDB51), 98.2\%(UCF101)  |
|ARG.(2019) | Graph-Conv, CNN | Sequential-based/<br/>Sampling | 91.0\%(Collective Activity), 92.6\%(Volleyball)  |
|AdaFrame.(2019) | CNN, LSTM | Sequential-based/<br/>RNN | 80.2\%(FCVID), 71.5\%(ActivityNet)  |
|CoST.(2019) | CNN | View-based/<br/>Combination | 77.5\%(Kinetics), 32.4\%(Moments in Time)  |

- Learning Actor Relation Graphs for Group Activity Recognition | 2019
- Potion: Pose motion representation for action recognition | 2018
- D3tw: Discriminative differentiable dynamic time warping for weakly supervised action alignment and segmentation | 2019
- Quo vadis, action recognition? a new model and the kinetics dataset | 2017
- Untrimmednets for weakly supervised action recognition and detection | 2017
- Cascaded Pyramid Mining Network for Weakly Supervised Temporal Action Localization | 2018
- Two-stream convolutional networks for action recognition in videos | 2014
- Contextual action recognition with r* cnn | 2015
- Convolutional two-stream network fusion for video action recognition | 2016
- Learnable pooling with context gating for video classification | 2017
- Deep local video feature for action recognition | 2017
- Deep temporal linear encoding networks | 2017
- Sequential deep learning for human action recognition | 2011
- Long-term recurrent convolutional networks for visual recognition and description | 2015
- Temporal segment networks: Towards good practices for deep action recognition | 2016
- 3D convolutional neural networks for human action recognition | 2012
- Learning spatiotemporal features with 3d convolutional networks | 2015
- Collaborative Spatiotemporal Feature Learning for Video Action Recognition | 2019
- AdaFrame: Adaptive Frame Selection for Fast Video Recognition | 2019
- Deep, convolutional, and recurrent models for human activity recognition using wearables | 2016
- Aenet: Learning deep audio features for video analysis | 2017
- Actions and attributes from wholes and parts | 2015
- PM-GANs: Discriminative Representation Learning for Action Recognition Using Partial-modalities | 2018
- Eco: Efficient convolutional network for online video understanding | 2018
- Large-scale video classification with convolutional neural networks | 2014
- Human action recognition using factorized spatio-temporal convolutional networks | 2015
- Learning spatio-temporal representation with pseudo-3d residual networks | 2017
- A closer look at spatiotemporal convolutions for action recognition | 2018
