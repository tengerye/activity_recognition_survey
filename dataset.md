|Dataset | Data type | Scenes | Annotation | Task | \#Examples/\#Classes | SOTA/benchmark  |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|\href{http://www.nada.kth.se/cvap/actions/}{KTH}~\cite{laptev2004recognizing} | Trimmed-video | Daily Living | Video-level | Action Recognition | 2391/6 | 98.9\%~\cite{al2017human} |
|\href{http://vhosts.eecs.umich.edu/vision//activity-dataset.html}{Collective Activity}~\cite{choi2009they} | Trimmed-video | Daily Living | Person/Group-level | \makecell{Group ActivityRecognition} | 44/5 | 91.0\%~\cite{wu2019learning} |
|\href{https://www.di.ens.fr/~laptev/actions/hollywood2/}{HOLLYWOOD2}~\cite{marszalek09} ||
|Trimmed-video | Movie | Video-level | Action Recognition | 3,669/12 | 73.7\%~\cite{fernando2015modeling} |
|\href{https://archive.ics.uci.edu/ml/datasets/Daphnet+Freezing+of+Gait}{Daphnet Gait}~\cite{bachlin2009potentials} | Signal-sequence | Sport | Signal-level | Action Recognition | 1,917,887/2 | 94.1\%~\cite{murad2017deep}  |
|\href{http://www.consortium.ri.cmu.edu/ckagree/}{CK}~\cite{lucey2010extended} | Still-image | Facial Expression | Image-level | \makecell{Facial ExpressionRecognition} | 327/7 | 88.7\%~\cite{gacav2017greedy} |
|\href{https://mmifacedb.eu/}{MMI}~\cite{valstar2010induced} | Video/Still-image | Facial Expression | Action Unit | \makecell{Facial ExpressionRecognition} | 2900/6 | 98.6\%~\cite{burkert2015dexpression} |
|\href{https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/shape/action/}{Pascal VOC Aactions}~\cite{everingham2010pascal} | Still-image | Comprehensive | Image-level | Action Recognition | 11,530/20 | 90.2\%~\cite{gkioxari2015contextual} |
|\href{http://www.cis.fordham.edu/wisdm/dataset.php}{WISDM}~\cite{kwapisz2011activity} | Signal-sequence | Daily Living | Signal-level | Action Recognition | 1098213/6 | 98.2\%~\cite{alsheikh2016deep}  |
|\href{http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/}{HMDB51}~\cite{kuehne2011hmdb} ||
|Trimmed-video | Daily Living | Video-level | Action Recognition | 6,766/51 | 82.1\%~\cite{zhu2018end} |
|\href{https://www.crcv.ucf.edu/data/UCF101.php}{UCF101}~\cite{soomro2012ucf101} ||
|Trimmed-video | Sport | Video-level | Action Recognition | 13,320/101 | 98.2\%~\cite{choutas2018potion} |
|\href{https://archive.ics.uci.edu/ml/datasets/opportunity+activity+recognition}{Opportunity}~\cite{chavarriaga2013opportunity} | Signal-sequence | Daily Living | Signal-level | Action Recognition | 701,366/16 | 91.8\%~\cite{li2018comparison}  |
|\href{https://archive.ics.uci.edu/ml/datasets/pamap2+physical+activity+monitoring}{PAMAP2}~\cite{zheng2014time} | Signal-sequence | Daily Living | Signal-level | Action Recognition | 2,844,868/18 | 91.0\%~\cite{twomey2018comprehensive}  |
|\href{https://cs.anu.edu.au/few/}{SFEW-2.0}~\cite{dhall2012collecting,dhall2014emotion} | Still-image | Facial Expression | Image-level | \makecell{Facial ExpressionRecognition} | 1394/7 | 58.1\%~\cite{acharya2018covariance} |
|\href{http://human-pose.mpi-inf.mpg.de/}{MPII}~\cite{andriluka20142d} | Still-image | Comprehensive | Image-level | Pose Estimation | 24920/410 | 92.1\%~\cite{ke2018multi} |
|\href{http://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/}{Breakfast Dataset}~\cite{kuehne2014language} ||
|Trimmed-video | Daily Living | Video-level | Action Recognition | 1,989/10 | 45.7\%~\cite{chang2019d3tw} |
|\href{http://www-personal.umich.edu/~ywchao/hico/}{HICO}~\cite{chao2015hico} | Still-image | Comprehensive | Image-level | \makecell{Human-Object Interaction Recognition} | 47774/117 | 47.1\%~\cite{li2019hake} |
|\href{http://activity-net.org/}{ACTIVITYNET-200}~\cite{caba2015activitynet} ||
|Untrimmed-video | Daily Living | Time-interval | Video Understanding | 19,994/200 | 91.3\%~\cite{wang2017untrimmednets}  |
|\href{https://github.com/mostafa-saad/deep-activity-rec}{Volleyball}~\cite{ibrahim2016hierarchical} | Trimmed-video | Sport | Video-level | \makecell{Group ActivityRecognition} | 4830/8 | 92.6\%~\cite{wu2019learning} |
|\href{https://allenai.org/plato/charades/}{Charades}~\cite{sigurdsson2016hollywood} ||
|Trimmed-video | Daily Living | Video-level | Action Recognition | 9,848/157 | 43.4\%~\cite{wu2019long} |
|\href{https://research.google.com/youtube8m/}{YouTube-8M}~\cite{abu2016youtube} ||
|Untrimmed-video | Comprehensive | Time-interval | Video Understanding | 6,100,000/3862 | 85.0\%~\cite{abu2016youtube} |
|\href{https://www.crcv.ucf.edu/THUMOS14/}{THUMOS14}~\cite{idrees2017thumos} | Untrimmed-video | Comprehensive | Time-interval | Video Understanding | 18404/101 | 82.2\%~\cite{wang2017untrimmednets}  |
|\href{https://deepmind.com/research/open-source/kinetics}{Kinetics}~\cite{kay2017kinetics} ||
|Trimmed-video |  Comprehensive | Video-level | Action Recognition | 300,000/700 | 82.8\%~\cite{ghadiyaram2019large} |
|\href{https://20bn.com/datasets/something-something}{Something-Something}~\cite{goyal2017something} ||
|Trimmed-video | Daily Living | Video-level | Action Recognition | 220,847/174 | 51.6\%~\cite{ghadiyaram2019large} |
|\href{http://bigvid.fudan.edu.cn/FCVID/}{FCVID}~\cite{jiang2017exploiting} ||
|Untrimmed-video | Comprehensive | Video-level | Action Recognition | 91,223/239 | 77.6\%~\cite{kang2018pivot} |
|\href{https://20bn.com/datasets/jester}{20BN-JESTER}~\cite{zhou2017temporalrelation} | Trimmed-video | Hand Gesture | Video-level | Action Recognition | 148000/27 | 94.8\%~\cite{zhou2017temporalrelation} |
|\href{http://www.escience.cn/people/gaochenqiang/Publications.html}{Infrared Visible}~\cite{wang2018pm} | Trimmed-video | Daily Living | Video-level | Action Recognition | 1200/12 | 80.2\%~\cite{wang2018pm} |
|\href{https://research.google.com/ava/}{AVA}~\cite{gu2018ava} ||
|Untrimmed-video | Movie | Time-interval | Video Understanding  | 57,600/80 | 27.2\%~\cite{wu2019long} |
|\href{https://epic-kitchens.github.io/2018}{Epic-kitchen}~\cite{Damen2018EPICKITCHENS} ||
|Trimmed-video | Daily Living | Video-level | Action Recognition | 432/149 | 34.5\%~\cite{ghadiyaram2019large} |
|\href{https://coin-dataset.github.io/}{COIN}~\cite{tang2019coin} | Untrimmed-video | Daily Living | Time-interval | Video Understanding | 11827/180 | 88.0\%~\cite{tang2019coin} |
|\href{http://moments.csail.mit.edu/}{Moments in Time}~\cite{monfortmoments} ||
|Trimmed-video | Comprehensive | Video-level | Action Recognition | 1,000,000/339 | 32.4\%~\cite{li2019collaborative}|
