|Dataset | Data type | Scenes | Annotation | Task | \#Examples/<br/>\#Classes | SOTA/<br/>benchmark  |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|[KTH](http://www.nada.kth.se/<br/>cvap/<br/>actions/) | Trimmed-video | Daily Living | Video-level | Action Recognition | 2391/<br/>6 | 98.9\% |
|[Collective Activity](http://vhosts.eecs.umich.edu/<br/>vision//activity-dataset.html) | Trimmed-video | Daily Living | Person/<br/>Group-level | Group ActivityRecognition | 44/<br/>5 | 91.0\% |
|[HOLLYWOOD2](https://www.di.ens.fr/~laptev/<br/>actions/<br/>hollywood2/) |Trimmed-video | Movie | Video-level | Action Recognition | 3,669/<br/>12 | 73.7\% |
|[Daphnet Gait](https://archive.ics.uci.edu/<br/>ml/<br/>datasets/<br/>Daphnet+Freezing+of+Gait) | Signal-sequence | Sport | Signal-level | Action Recognition | 1,917,887/<br/>2 | 94.1\%  |
|[CK](http://www.consortium.ri.cmu.edu/<br/>ckagree/) | Still-image | Facial Expression | Image-level | Facial ExpressionRecognition | 327/<br/>7 | 88.7\% |
|[MMI](https://mmifacedb.eu/) | Video/<br/>Still-image | Facial Expression | Action Unit | Facial ExpressionRecognition | 2900/<br/>6 | 98.6\% |
|[Pascal VOC Aactions](https://www2.eecs.berkeley.edu/<br/>Research/<br/>Projects/<br/>CS/<br/>vision/<br/>shape/<br/>action/) | Still-image | Comprehensive | Image-level | Action Recognition | 11,530/<br/>20 | 90.2\% |
|[WISDM](http://www.cis.fordham.edu/<br/>wisdm/<br/>dataset.php) | Signal-sequence | Daily Living | Signal-level | Action Recognition | 1098213/<br/>6 | 98.2\%  |
|[HMDB51](http://serre-lab.clps.brown.edu/<br/>resource/<br/>hmdb-a-large-human-motion-database/) |Trimmed-video | Daily Living | Video-level | Action Recognition | 6,766/<br/>51 | 82.1\% |
|[UCF101](https://www.crcv.ucf.edu/<br/>data/<br/>UCF101.php) |Trimmed-video | Sport | Video-level | Action Recognition | 13,320/<br/>101 | 98.2\% |
|[Opportunity](https://archive.ics.uci.edu/<br/>ml/<br/>datasets/<br/>opportunity+activity+recognition) | Signal-sequence | Daily Living | Signal-level | Action Recognition | 701,366/<br/>16 | 91.8\%  |
|[PAMAP2](https://archive.ics.uci.edu/<br/>ml/<br/>datasets/<br/>pamap2+physical+activity+monitoring) | Signal-sequence | Daily Living | Signal-level | Action Recognition | 2,844,868/<br/>18 | 91.0\%  |
|[SFEW-2.0](https://cs.anu.edu.au/<br/>few/) | Still-image | Facial Expression | Image-level | Facial ExpressionRecognition | 1394/<br/>7 | 58.1\% |
|[MPII](http://human-pose.mpi-inf.mpg.de/) | Still-image | Comprehensive | Image-level | Pose Estimation | 24920/<br/>410 | 92.1\% |
|[Breakfast Dataset](http://serre-lab.clps.brown.edu/<br/>resource/<br/>breakfast-actions-dataset/) |Trimmed-video | Daily Living | Video-level | Action Recognition | 1,989/<br/>10 | 45.7\% |
|[HICO](http://www-personal.umich.edu/~ywchao/<br/>hico/) | Still-image | Comprehensive | Image-level | Human-Object Interaction Recognition | 47774/<br/>117 | 47.1\% |
|[ACTIVITYNET-200](http://activity-net.org/) |Untrimmed-video | Daily Living | Time-interval | Video Understanding | 19,994/<br/>200 | 91.3\%  |
|[Volleyball](https://github.com/<br/>mostafa-saad/<br/>deep-activity-rec) | Trimmed-video | Sport | Video-level | Group ActivityRecognition | 4830/<br/>8 | 92.6\% |
|[Charades](https://allenai.org/<br/>plato/<br/>charades/) |Trimmed-video | Daily Living | Video-level | Action Recognition | 9,848/<br/>157 | 43.4\% |
|[YouTube-8M](https://research.google.com/<br/>youtube8m/) |Untrimmed-video | Comprehensive | Time-interval | Video Understanding | 6,100,000/<br/>3862 | 85.0\% |
|[THUMOS14](https://www.crcv.ucf.edu/<br/>THUMOS14/) | Untrimmed-video | Comprehensive | Time-interval | Video Understanding | 18404/<br/>101 | 82.2\%  |
|[Kinetics](https://deepmind.com/<br/>research/<br/>open-source/<br/>kinetics) |Trimmed-video |  Comprehensive | Video-level | Action Recognition | 300,000/<br/>700 | 82.8\% |
|[Something-Something](https://20bn.com/<br/>datasets/<br/>something-something) |Trimmed-video | Daily Living | Video-level | Action Recognition | 220,847/<br/>174 | 51.6\% |
|[FCVID](http://bigvid.fudan.edu.cn/<br/>FCVID/) |Untrimmed-video | Comprehensive | Video-level | Action Recognition | 91,223/<br/>239 | 77.6\% |
|[20BN-JESTER](https://20bn.com/<br/>datasets/<br/>jester) | Trimmed-video | Hand Gesture | Video-level | Action Recognition | 148000/<br/>27 | 94.8\% |
|[Infrared Visible](http://www.escience.cn/<br/>people/<br/>gaochenqiang/<br/>Publications.html) | Trimmed-video | Daily Living | Video-level | Action Recognition | 1200/<br/>12 | 80.2\% |
|[AVA](https://research.google.com/<br/>ava/) |Untrimmed-video | Movie | Time-interval | Video Understanding  | 57,600/<br/>80 | 27.2\% |
|[Epic-kitchen](https://epic-kitchens.github.io/<br/>2018) |Trimmed-video | Daily Living | Video-level | Action Recognition | 432/<br/>149 | 34.5\% |
|[COIN](https://coin-dataset.github.io/) | Untrimmed-video | Daily Living | Time-interval | Video Understanding | 11827/<br/>180 | 88.0\% |
|[Moments in Time](http://moments.csail.mit.edu/) |Trimmed-video | Comprehensive | Video-level | Action Recognition | 1,000,000/<br/>339 | 32.4\% |

- Activity recognition using cell phone accelerometers | 2011
- A hierarchical deep temporal model for group activity recognition | 2016
- Learning Actor Relation Graphs for Group Activity Recognition | 2019
- What are they doing?: Collective activity classification using spatio-temporal relationship among people | 2009
- Covariance pooling for facial expression recognition | 2018
- Dexpression: Deep convolutional neural network for expression recognition | 2015
- Induced disgust, happiness and surprise: an addition to the mmi facial expression database | 2010
- Greedy search for descriptive spatial face features | 2017
- The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression | 2010
- Multi-scale structure-aware network for human pose estimation | 2018
- HAKE: Human Activity Knowledge Engine | 2019
- 2d human pose estimation: New benchmark and state of the art analysis | 2014
- Hico: A benchmark for recognizing human-object interactions in images | 2015
- The pascal visual object classes (voc) challenge | 2010
- The THUMOS challenge on action recognition for videos “in the wild” | 2017
- Human actions recognition based on 3D deep neural network | 2017
- Exploiting feature and class relationships in video categorization with regularized deep neural networks | 2017
- A comprehensive study of activity recognition using accelerometers | 2018
- Comparison of feature learning methods for human activity recognition using wearable sensors | 2018
- Time series classification using multi-channels deep convolutional neural networks | 2014
- The Opportunity challenge: A benchmark database for on-body sensor-based activity recognition | 2013
- Potentials of enhanced context awareness in wearable assistants for Parkinson's disease patients with the freezing of gait syndrome | 2009
- Coin: A large-scale dataset for comprehensive instructional video analysis | 2019
- UCF101: A dataset of 101 human actions classes from videos in the wild | 2012
- The language of actions: Recovering the syntax and semantics of goal-directed human activities | 2014
- Pivot correlational neural network for multimodal video categorization | 2018
- Temporal Relational Reasoning in Videos | 2018
- Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding | 2016
- AVA: A video dataset of spatio-temporally localized atomic visual actions | 2018
- The kinetics human action video dataset | 2017
- Scaling Egocentric Vision: The EPIC-KITCHENS Dataset | 2018
- The" Something Something" Video Database for Learning and Evaluating Visual Common Sense. | 2017
- Recognizing human actions: a local SVM approach | 2004
- Actions in Context | 2009
- Deep recurrent neural networks for human activity recognition | 2017
- Moments in Time Dataset: one million videos for event understanding | 2019
- ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding | 2015
- End-to-end video-level representation learning for action recognition | 2018
- HMDB: a large video database for human motion recognition | 2011
- Potion: Pose motion representation for action recognition | 2018
- D3tw: Discriminative differentiable dynamic time warping for weakly supervised action alignment and segmentation | 2019
- Long-term feature banks for detailed video understanding | 2019
- Large-scale weakly-supervised pre-training for video action recognition | 2019
- Modeling video evolution for action recognition | 2015
- Untrimmednets for weakly supervised action recognition and detection | 2017
- Youtube-8m: A large-scale video classification benchmark | 2016
- Contextual action recognition with r* cnn | 2015
- Collaborative Spatiotemporal Feature Learning for Video Action Recognition | 2019
- PM-GANs: Discriminative Representation Learning for Action Recognition Using Partial-modalities | 2018
- Deep activity recognition models with triaxial accelerometers | 2016

