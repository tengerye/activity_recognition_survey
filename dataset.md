|Dataset | Data type | Scenes | Annotation | Task | \#Examples/\#Classes | SOTA/benchmark  |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|[KTH](http://www.nada.kth.se/cvap/actions/)| Trimmed-video | Daily Living | Video-level | Action Recognition | 2391/6 | 98.9\%~\cite{al2017human} |
|[Collective Activity](http://vhosts.eecs.umich.edu/vision//activity-dataset.html)| Trimmed-video | Daily Living | Person/Group-level | \makecell{Group ActivityRecognition} | 44/5 | 91.0\%~\cite{wu2019learning} |
|[HOLLYWOOD2](https://www.di.ens.fr/~laptev/actions/hollywood2/)||
|[rimmed-video](ed-video)| Movie | Video-level | Action Recognition | 3,669/12 | 73.7\%~\cite{fernando2015modeling} |
|[Daphnet Gait](https://archive.ics.uci.edu/ml/datasets/Daphnet+Freezing+of+Gait)| Signal-sequence | Sport | Signal-level | Action Recognition | 1,917,887/2 | 94.1\%~\cite{murad2017deep}  |
|[CK](http://www.consortium.ri.cmu.edu/ckagree/)| Still-image | Facial Expression | Image-level | \makecell{Facial ExpressionRecognition} | 327/7 | 88.7\%~\cite{gacav2017greedy} |
|[MMI](https://mmifacedb.eu/)| Video/Still-image | Facial Expression | Action Unit | \makecell{Facial ExpressionRecognition} | 2900/6 | 98.6\%~\cite{burkert2015dexpression} |
|[Pascal VOC Aactions](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/shape/action/)| Still-image | Comprehensive | Image-level | Action Recognition | 11,530/20 | 90.2\%~\cite{gkioxari2015contextual} |
|[WISDM](http://www.cis.fordham.edu/wisdm/dataset.php)| Signal-sequence | Daily Living | Signal-level | Action Recognition | 1098213/6 | 98.2\%~\cite{alsheikh2016deep}  |
|[HMDB51](http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/)||
|[rimmed-video](ed-video)| Daily Living | Video-level | Action Recognition | 6,766/51 | 82.1\%~\cite{zhu2018end} |
|[UCF101](https://www.crcv.ucf.edu/data/UCF101.php)||
|[rimmed-video](ed-video)| Sport | Video-level | Action Recognition | 13,320/101 | 98.2\%~\cite{choutas2018potion} |
|[Opportunity](https://archive.ics.uci.edu/ml/datasets/opportunity+activity+recognition)| Signal-sequence | Daily Living | Signal-level | Action Recognition | 701,366/16 | 91.8\%~\cite{li2018comparison}  |
|[PAMAP2](https://archive.ics.uci.edu/ml/datasets/pamap2+physical+activity+monitoring)| Signal-sequence | Daily Living | Signal-level | Action Recognition | 2,844,868/18 | 91.0\%~\cite{twomey2018comprehensive}  |
|[SFEW-2.0](https://cs.anu.edu.au/few/)| Still-image | Facial Expression | Image-level | \makecell{Facial ExpressionRecognition} | 1394/7 | 58.1\%~\cite{acharya2018covariance} |
|[MPII](http://human-pose.mpi-inf.mpg.de/)| Still-image | Comprehensive | Image-level | Pose Estimation | 24920/410 | 92.1\%~\cite{ke2018multi} |
|[Breakfast Dataset](http://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/)||
|[rimmed-video](ed-video)| Daily Living | Video-level | Action Recognition | 1,989/10 | 45.7\%~\cite{chang2019d3tw} |
|[HICO](http://www-personal.umich.edu/~ywchao/hico/)| Still-image | Comprehensive | Image-level | \makecell{Human-Object Interaction Recognition} | 47774/117 | 47.1\%~\cite{li2019hake} |
|[ACTIVITYNET-200](http://activity-net.org/)||
|[ntrimmed-video](mmed-video)| Daily Living | Time-interval | Video Understanding | 19,994/200 | 91.3\%~\cite{wang2017untrimmednets}  |
|[Volleyball](https://github.com/mostafa-saad/deep-activity-rec)| Trimmed-video | Sport | Video-level | \makecell{Group ActivityRecognition} | 4830/8 | 92.6\%~\cite{wu2019learning} |
|[Charades](https://allenai.org/plato/charades/)||
|[rimmed-video](ed-video)| Daily Living | Video-level | Action Recognition | 9,848/157 | 43.4\%~\cite{wu2019long} |
|[YouTube-8M](https://research.google.com/youtube8m/)||
|[ntrimmed-video](mmed-video)| Comprehensive | Time-interval | Video Understanding | 6,100,000/3862 | 85.0\%~\cite{abu2016youtube} |
|[THUMOS14](https://www.crcv.ucf.edu/THUMOS14/)| Untrimmed-video | Comprehensive | Time-interval | Video Understanding | 18404/101 | 82.2\%~\cite{wang2017untrimmednets}  |
|[Kinetics](https://deepmind.com/research/open-source/kinetics)||
|[rimmed-video](ed-video)|  Comprehensive | Video-level | Action Recognition | 300,000/700 | 82.8\%~\cite{ghadiyaram2019large} |
|[Something-Something](https://20bn.com/datasets/something-something)||
|[rimmed-video](ed-video)| Daily Living | Video-level | Action Recognition | 220,847/174 | 51.6\%~\cite{ghadiyaram2019large} |
|[FCVID](http://bigvid.fudan.edu.cn/FCVID/)||
|[ntrimmed-video](mmed-video)| Comprehensive | Video-level | Action Recognition | 91,223/239 | 77.6\%~\cite{kang2018pivot} |
|[20BN-JESTER](https://20bn.com/datasets/jester)| Trimmed-video | Hand Gesture | Video-level | Action Recognition | 148000/27 | 94.8\%~\cite{zhou2017temporalrelation} |
|[Infrared Visible](http://www.escience.cn/people/gaochenqiang/Publications.html)| Trimmed-video | Daily Living | Video-level | Action Recognition | 1200/12 | 80.2\%~\cite{wang2018pm} |
|[AVA](https://research.google.com/ava/)||
|[ntrimmed-video](mmed-video)| Movie | Time-interval | Video Understanding  | 57,600/80 | 27.2\%~\cite{wu2019long} |
|[Epic-kitchen](https://epic-kitchens.github.io/2018)||
|[rimmed-video](ed-video)| Daily Living | Video-level | Action Recognition | 432/149 | 34.5\%~\cite{ghadiyaram2019large} |
|[COIN](https://coin-dataset.github.io/)| Untrimmed-video | Daily Living | Time-interval | Video Understanding | 11827/180 | 88.0\%~\cite{tang2019coin} |
|[Moments in Time](http://moments.csail.mit.edu/)||
|[rimmed-video](ed-video)| Comprehensive | Video-level | Action Recognition | 1,000,000/339 | 32.4\%~\cite{li2019collaborative}|
